{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy实现浅层神经网络\n",
    "\n",
    "\n",
    "实践部分将搭建神经网络，包含一个隐藏层，实验将会展现出与Logistic回归的不同之处。\n",
    "\n",
    "实验将使用两层神经网络实现对“花”型图案的分类，如图所示，图中的点包含红点（y=0）和蓝点（y=1）还有点的坐标信息，实验将通过以下步骤完成对两种点的分类，使用Numpy实现。\n",
    "\n",
    "- 输入样本；\n",
    "\n",
    "- 搭建神经网络；\n",
    "\n",
    "- 初始化参数；\n",
    "\n",
    "- 训练，包括前向传播与后向传播（即BP算法）；\n",
    "\n",
    "- 得出训练后的参数；\n",
    "\n",
    "- 根据训练所得参数，绘制两类点边界曲线。\n",
    "\n",
    "<img src=\"image/data.png\" style=\"width:400px;height:300px;\">\n",
    "\n",
    "该实验将使用Python原生库实现两层神经网络的搭建，完成分类。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - 引用库\n",
    "\n",
    "首先，载入几个需要用到的库，它们分别是：\n",
    "- numpy：一个python的基本库，用于科学计算\n",
    "- planar_utils：定义了一些工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package imports\n",
    "import numpy as np\n",
    "from planar_utils import plot_decision_boundary, sigmoid, load_planar_dataset, load_extra_datasets\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1) # set a seed so that the results are consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - 载入数据并观察纬度\n",
    "\n",
    "载入数据后，输出维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (2, 320)\n",
      "The shape of Y is: (1, 320)\n"
     ]
    }
   ],
   "source": [
    "#载入数据\n",
    "train_x, train_y, test_x, test_y = planar_utils.load_planar_dataset()\n",
    "#输出维度\n",
    "shape_X = train_x.shape\n",
    "shape_Y = train_y.shape\n",
    "print ('The shape of X is: ' + str(shape_X))\n",
    "print ('The shape of Y is: ' + str(shape_Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由输出可知每组输入坐标包含两个值，包含一个值，共320组数据（测试集在训练集基础上增加80组数据，共400组）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - 神经网络模型\n",
    "\n",
    "下面开始搭建神经网络模型，我们采用两层神经网络实验，隐藏层包含4个节点，使用tanh激活函数；输出层包含一个节点，使用Sigmoid激活函数，结果小于0.5即认为是0，否则认为是1。\n",
    "\n",
    "** 神经网络结构 **\n",
    "\n",
    "下面用代码实现神经网络结构，首先确定神经网络的结构，即获取相关数据维度，并设置隐藏层节点个数（本实验设置4个隐藏层节点），用以初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义各层规模函数\n",
    "def layer_sizes(X, Y):\n",
    "    \"\"\"\n",
    "    参数含义:\n",
    "    X -- 输入的数据\n",
    "    Y -- 输出值\n",
    "    \n",
    "    返回值:\n",
    "    n_x -- 输入层节点数\n",
    "    n_h -- 隐藏层节点数\n",
    "    n_y -- 输出层节点数\n",
    "    \"\"\"\n",
    "    \n",
    "    n_x = X.shape[0] #输入层大小（节点数）\n",
    "    n_h = 4\n",
    "    n_y = Y.shape[0] #输出层大小（节点数）\n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 初始化模型参数 **\n",
    "\n",
    "获取相关维度信息后，开始初始化参数，定义相关函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数：初始化参数\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    n_x -- 输入层大小\n",
    "    n_h -- 隐藏层大小\n",
    "    n_y -- 输出层大小\n",
    "    \n",
    "    返回值:\n",
    "    params -- 一个包含所有参数的python字典:\n",
    "                    W1 -- （隐藏层）权重，维度是 (n_h, n_x)\n",
    "                    b1 -- （隐藏层）偏移量，维度是 (n_h, 1)\n",
    "                    W2 -- （输出层）权重，维度是 (n_y, n_h)\n",
    "                    b2 -- （输出层）偏移量，维度是 (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(2) # 设置随机种子\n",
    "    \n",
    "    #随机初始化参数\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.zeros((n_h, 1))\n",
    "    W2 = np.random.randn(n_y, n_h) * 0.01\n",
    "    b2 = np.zeros((n_y, 1))\n",
    "    \n",
    "    \n",
    "    assert (W1.shape == (n_h, n_x))\n",
    "    assert (b1.shape == (n_h, 1))\n",
    "    assert (W2.shape == (n_y, n_h))\n",
    "    assert (b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 前向传播与后向传播 **\n",
    "\n",
    "获取输入数据，参数初始化完成后，可以开始前向传播的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数：前向传播\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    X -- 输入值 \n",
    "    parameters -- 一个python字典，包含计算所需全部参数（是initialize_parameters函数的输出）    \n",
    "    返回值:\n",
    "    A2 -- 模型输出值\n",
    "    cache -- 一个字典，包含 \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    \n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    #计算中间量和节点值    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = 1/(1+np.exp(-Z2))\n",
    "    \n",
    "    \n",
    "    assert(A2.shape == (1, X.shape[1]))\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前向传播最后可得出模型输出值（即代码中的A2），即可计算成本函数cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数：成本函数\n",
    "\n",
    "def compute_cost(A2, Y, parameters):\n",
    "    \"\"\"\n",
    "   根据第三章给出的公式计算成本\n",
    "    \n",
    "    参数:\n",
    "A2 -- 模型输出值    \n",
    "Y -- 真实值\n",
    "    parameters -- 一个python字典包含参数 W1, b1, W2和b2\n",
    "    \n",
    "    返回值:\n",
    "    cost -- 成本函数\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1] #样本个数\n",
    "\n",
    "    #计算成本\n",
    "    logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1 - A2), 1 - Y)\n",
    "    cost =  -1. / m * np.sum(logprobs)\n",
    "    \n",
    "    cost = np.squeeze(cost)     # 确保维度的正确性                        \n",
    "    assert(isinstance(cost, float))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算了成本函数，可以开始后向传播的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义函数：后向传播\n",
    "\n",
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    \"\"\"    \n",
    "    参数:\n",
    "    parameters -- 一个python字典，包含所有参数 \n",
    "    cache -- 一个python字典包含\"Z1\", \"A1\", \"Z2\"和\"A2\".\n",
    "    X -- 输入值\n",
    "    Y -- 真实值\n",
    "    \n",
    "    返回值:\n",
    "    grads -- 一个python字典包含所有参数的梯度\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "  \n",
    "    #首先从\"parameters\"获取W1,W2\n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "        \n",
    "    # 从\"cache\"中获取A1,A2\n",
    "    A1 = cache[\"A1\"]\n",
    "    A2 = cache[\"A2\"]\n",
    "    \n",
    "    #后向传播: 计算dW1, db1, dW2, db2. \n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = 1. / m * np.dot(dZ2, A1.T)\n",
    "    db2 = 1. / m * np.sum(dZ2, axis = 1, keepdims = True)\n",
    "    dZ1 = np.dot(W2.T, dZ2) * (1 - np.power(A1, 2))\n",
    "    dW1 = 1. / m * np.dot(dZ1, X.T)\n",
    "    db1 = 1. / m * np.sum(dZ1, axis = 1, keepdims = True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过后向传播获取梯度后，可以根据梯度下降公式更新参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate = 1.2):\n",
    "    \"\"\"\n",
    "    使用梯度更新参数\n",
    "    \n",
    "    参数:\n",
    "    parameters -- 包含所有参数的python字典 \n",
    "    grads -- 包含所有参数梯度的python字典 \n",
    "    \n",
    "    返回值:\n",
    "    parameters -- 包含更新后参数的python \n",
    "    \"\"\"\n",
    "    #从\"parameters\"中读取全部参数\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # 从\"grads\"中读取全部梯度\n",
    "    dW1 = grads[\"dW1\"]\n",
    "    db1 = grads[\"db1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    db2 = grads[\"db2\"]\n",
    "    \n",
    "    #更新参数\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 神经网络模型 **\n",
    "\n",
    "前向传播、成本函数计算和后向传播构成一个完整的神经网络，将上述函数组合，构建一个神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义函数：神经网络模型\n",
    "def nn_model(X, Y, n_h, num_iterations = 10000, print_cost=False):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    X -- 输入值\n",
    "    Y -- 真实值\n",
    "    n_h -- 隐藏层大小/节点数\n",
    "    num_iterations -- 训练次数\n",
    "    print_cost -- 设置为True，则每1000次训练打印一次成本函数值\n",
    "    \n",
    "    返回值:\n",
    "parameters -- 训练结束，更新后的参数值    \n",
    "\"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[2]\n",
    "    \n",
    "    #根据n_x, n_h, n_y初始化参数，并取出W1,b1,W2,b2   \n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    \n",
    "    for i in range(0, num_iterations):      \n",
    "       \n",
    "        #前向传播， 输入: \"X, parameters\". 输出: \"A2, cache\".\n",
    "        A2, cache = forward_propagation(X, parameters)\n",
    "        \n",
    "        #成本计算. 输入: \"A2, Y, parameters\". 输出: \"cost\".\n",
    "        cost = compute_cost(A2, Y, parameters)\n",
    " \n",
    "        #后向传播， 输入: \"parameters, cache, X, Y\". 输出: \"grads\".\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    " \n",
    "        #参数更新. 输入: \"parameters, grads\". 输出: \"parameters\".\n",
    "        parameters = update_parameters(parameters, grads)\n",
    "        \n",
    "        #每1000次训练打印一次成本函数值\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 预测 ** \n",
    "\n",
    "通过上述模型可以训练得出最后的参数，此时需检测其准确率，用训练后的参数预测训练的输出，大于0.5的值视作1，否则视作0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义函数：预测\n",
    "def predict(parameters, X):\n",
    "    \"\"\"\n",
    "    使用训练所得参数，对每个训练样本进行预测\n",
    "    \n",
    "    参数:\n",
    "    parameters -- 保安所有参数的python字典 \n",
    "    X -- 输入值\n",
    "    \n",
    "    返回值：\n",
    "    predictions -- 模型预测值向量(红色: 0 / 蓝色: 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    #使用训练所得参数进行前向传播计算，并将模型输出值转化为预测值（大于0.5视作1，即True）\n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = A2 > 0.5\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面对获取的数据进行训练，并输出准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693067\n",
      "Cost after iteration 1000: 0.274649\n",
      "Cost after iteration 2000: 0.256508\n",
      "Cost after iteration 3000: 0.246463\n",
      "Cost after iteration 4000: 0.240013\n",
      "Cost after iteration 5000: 0.235597\n",
      "Cost after iteration 6000: 0.232441\n",
      "Cost after iteration 7000: 0.230102\n",
      "Cost after iteration 8000: 0.228313\n",
      "Cost after iteration 9000: 0.226908\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "c of shape (1, 320) not acceptable as a color sequence for x with size 320, y with size 320",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ec08cec1f3bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#绘制分类边界\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplot_decision_boundary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Decision Boundary for hidden layer size \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/paddle/4.shallow_neural_network/planar_utils.pyc\u001b[0m in \u001b[0;36mplot_decision_boundary\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpectral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#定义Sigmoid函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3376\u001b[0m                          \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3377\u001b[0m                          \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3378\u001b[0;31m                          edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3379\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3380\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/matplotlib/axes/_axes.pyc\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   3986\u001b[0m                 msg = (\"c of shape {0} not acceptable as a color sequence \"\n\u001b[1;32m   3987\u001b[0m                        \"for x with size {1}, y with size {2}\")\n\u001b[0;32m-> 3988\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3989\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3990\u001b[0m             \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m  \u001b[0;31m# use cmap, norm after collection is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: c of shape (1, 320) not acceptable as a color sequence for x with size 320, y with size 320"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24f8eca450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#建立神经网络模型\n",
    "parameters = nn_model(train_x, train_y, n_h = 4, num_iterations = 10000, print_cost=True)\n",
    "\n",
    "#绘制分类边界\n",
    "plot_decision_boundary(lambda x: predict(parameters, x.T), train_x, train_y)\n",
    "plt.title(\"Decision Boundary for hidden layer size \" + str(4))\n",
    " \n",
    "# 预测训练集\n",
    "print('Train Accuracy: %d' % float((np.dot(train_y, predictions.T) +\n",
    "                                    np.dot(1 - train_y, 1 - predictions.T)) /\n",
    "                                    float(train_y.size) * 100) + '%')\n",
    "# 预测测试集\n",
    "predictions = predict(parameters, test_x)\n",
    "print('Test Accuracy: %d' % float((np.dot(test_y, predictions.T) +\n",
    "                                    np.dot(1 - test_y, 1 - predictions.T)) /\n",
    "                                    float(test_y.size) * 100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对比逻辑回归47%的准确率和分类结果图，神经网络分类的结果提高了不少，这是因为神经网络增加的隐藏层，为模型训练提供了更多选择，使得神经网络能拟合更加复杂的模型，对于更加复杂的图案分类更加准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
